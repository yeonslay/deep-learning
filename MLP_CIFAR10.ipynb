{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nIZA4EGDQ4kg",
        "outputId": "d102ce2b-2cb0-4fb0-9ceb-d64be2b7140b"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "100%|██████████| 170M/170M [00:15<00:00, 10.8MB/s]\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "epochs = 100, batch_size = 64, iters = 78200 수행완료!\n",
            "Accuracy : 58.79 %\n"
          ]
        }
      ],
      "source": [
        "# PyTorch 라이브러리 import\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torchvision import transforms, datasets\n",
        "\n",
        "\n",
        "# CIFAR-10 training set 및 test set 불러오기\n",
        "train_dataset = datasets.CIFAR10(root = '.', train = True, download = True,\n",
        "                                transform = transforms.ToTensor())\n",
        "test_dataset = datasets.CIFAR10(root = '.', train = False, download = True,\n",
        "                                transform = transforms.ToTensor())\n",
        "\n",
        "\n",
        "class MLP(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(MLP, self).__init__()\n",
        "    torch.manual_seed(2025)\n",
        "    # MLP 구성\n",
        "    self.affine1 = nn.Linear(3*32*32, 1024)\n",
        "    self.bn1 = nn.BatchNorm1d(1024)\n",
        "    self.activation1 = nn.GELU()\n",
        "    self.drop1 = nn.Dropout(0.3)\n",
        "\n",
        "    self.affine2 = nn.Linear(1024, 512)\n",
        "    self.bn2 = nn.BatchNorm1d(512)\n",
        "    self.activation2 = nn.GELU()\n",
        "    self.drop2 = nn.Dropout(0.3)\n",
        "\n",
        "    self.affine3 = nn.Linear(512, 256)\n",
        "    self.bn3 = nn.BatchNorm1d(256)\n",
        "    self.activation3 = nn.GELU()\n",
        "    self.drop3 = nn.Dropout(0.2)\n",
        "\n",
        "    self.affine4 = nn.Linear(256, 128)\n",
        "    self.bn4 = nn.BatchNorm1d(128)\n",
        "    self.activation4 = nn.GELU()\n",
        "    self.drop4 = nn.Dropout(0.2)\n",
        "\n",
        "    self.affine5 = nn.Linear(128, 10)\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = x.view(-1, 32*32*3) # Flatten\n",
        "\n",
        "    x = self.affine1(x)\n",
        "    x = self.bn1(x)\n",
        "    x = self.activation1(x)\n",
        "    x = self.drop1(x)\n",
        "\n",
        "    x = self.affine2(x)\n",
        "    x = self.bn2(x)\n",
        "    x = self.activation2(x)\n",
        "    x = self.drop2(x)\n",
        "\n",
        "    x = self.affine3(x)\n",
        "    x = self.bn3(x)\n",
        "    x = self.activation3(x)\n",
        "    x = self.drop3(x)\n",
        "\n",
        "    x = self.affine4(x)\n",
        "    x = self.bn4(x)\n",
        "    x = self.activation4(x)\n",
        "    x = self.drop4(x)\n",
        "\n",
        "    x = self.affine5(x)\n",
        "    return x\n",
        "\n",
        "model = MLP().cuda()\n",
        "\n",
        "# 학습 수행\n",
        "batchsize = 64\n",
        "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
        "                                           batch_size = batchsize, shuffle=True)\n",
        "learning_rate = 0.001\n",
        "optimizer = torch.optim.AdamW(model.parameters(), lr=0.001, weight_decay=1e-4)\n",
        "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=30)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "num_epochs = 100\n",
        "iter = 0\n",
        "model.train()\n",
        "for epoch in range(num_epochs):\n",
        "  for image, label in train_loader:\n",
        "    image = image.cuda()\n",
        "    label = label.cuda()\n",
        "\n",
        "    output = model(image)\n",
        "    loss = criterion(output, label)\n",
        "    optimizer.zero_grad()\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    iter += 1\n",
        "print(f'epochs = {num_epochs}, batch_size = {batchsize}, iters = {iter} 수행완료!')\n",
        "\n",
        "# 모델 평가\n",
        "\n",
        "batchsize = 64\n",
        "test_loader = torch.utils.data.DataLoader(dataset=test_dataset,\n",
        "                                           batch_size=batchsize, shuffle=True)\n",
        "\n",
        "num_correct = 0\n",
        "\n",
        "model.eval()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for image, label in test_loader:\n",
        "    image = image.cuda()\n",
        "    label = label.cuda()\n",
        "    output = model(image)\n",
        "    pred = output.argmax(dim=1)\n",
        "    num_correct += (pred == label).sum()\n",
        "\n",
        "print(f'Accuracy : {num_correct / len(test_dataset) * 100:.2f} %')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WgYaY9gFQ7Dq"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
